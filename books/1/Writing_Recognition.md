# Recognition of Written Text

Recognizing text written by a pen seems to be a very obvious direction to look in while researching input methods.  Why not take one of  the most prevailing input methods and use it as a model. Turns out that in practice it's much more difficult than you'd hope.   

Recognizing alphabets turns out to be quite trick for a computer to do. Even though it seemed to be the obvious path to go for  tablet when  most mobile devices had styluses and resistive touchscreen, it seems seems appealing with capacitive multi-touch screens.

Stenography most used in courts nowadays used specialized machines, see chapter on chording, before this however they used a pens albeit with different symbols. Continuing along this trajectory it seems  quite reasonable to try to design a new alphabet that would suit the medium   better. Just as symbols meant to be carved into wood or stone are different from those meant for paper.

## Edgewrite
Edgewrite is a very interesting take on this.  The PhD dissertation on the subject is well written and well worth a read. It covers some very interesting topics. Based on Universal Design, the idea is to see disability as a spectrum. Optimizations made  for people with extreme  disability will also improve for other people  on the spectrum. For instance you could see walking as a temporary disability in terms  of using a  computing device.  Improvement meant for  people  with say tremor translates to an improvement for everyone in that sense.

We've covered Fitt's law which is a fundamental principle in user interface design before. In short it states that the further away and  the smaller a object is the harder it is to select. By using the edges of a surface  however it can be cheated, since the  amount of  overshoot is ignored. This is the basis of the Edgewrite alphabet. 

The alphabet is  based on roman symbols but condensed so that they can be  described by movements  hitting  four edges. The symbols never end at the upper left corner, instead ending a letter on this edge makes it an upper case letter.

Jacob O. Wobbrock that wrote his PhD on Edgewrite, does a very good job of providing a theoretical framework for comparing input methods. What is of interest here is the power law  of learning, which is crucial for measuring learning of new input methods.

## Word level prediction
If the recognition  is  not done on  a symbol to symbol level but rather on a word  level,  it  is possible to deduce a set of  likely words to choose  from. This might improve prediction success.

## Further development
The work that Jacob O. Wobbrock have done is quite impressive. It would be possible to take the same methodology and juxtapose it to another field. Say gesture recognition for a haptic / glove based system.

## Links and Resources
[Microsoft Research: Demonstration of Delay](https://youtu.be/vOvQCPLkPt4)
[Edgewrite, University of Washington](http://depts.washington.edu/ewrite/)
[Edgewrite, PhD Dissertation,   Jacob O. Wobbrock](http://depts.washington.edu/ewrite/)
