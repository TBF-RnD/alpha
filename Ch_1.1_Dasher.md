# Dasher input method
The first input method up for discussion, just happpens to be one of the most recent. It was originally developed by Davaid JC McKay and David Ward. David Ward wrote his PhD on the subject which you can find below. Currently it is being administered by the inference group and is supported by the Gatsby Foundation and the European Commission. 

At first glance the Dasher input method looks very strange. However if you think of as a top down racing game, you'll understand it quite quickly.  For comparison imagine the shock for someone who was used to writing with a pen for his entire life when  presented with a typewriter\*. When presented with using the method however most people catch on  quite quickly.  

There we have the first argument in favour for using the Dasher input method. It can be used with an input controller that only supports one axis. Practically a two axis input method is used, however it can be used with only one input signal. As such it fits very well into the cateogry of software aimed at people with disabilities, and has been applied for this successfully.  

## The math magic
Still to fully understand Dasher a bit of math is necessery. Each of the symbols in the alphabet is presented in alphabetical order, so nothing spectacular on that front. They are however of  different size. The size that they are given are calculated on the basis on their probability of appearing after what you have just wrote.   

Without taking the previous letter into account the letter E have a probability of around 10-12% in English text. Z on the other hand is the least probable with a probabilty of 0.07%. This means that if we make it easier for the user to select an E than a Z, given the correct frequency distribution we  will on average see an improvement in writing speed.  

The genius here is that the onscreen representation basically is arithmetic coding. Where symbols that are frequent are replaced with short replacements and less frequent with longer. This only work if the distribution has the correct properties of course. For completely random input where each symbol has the same probability it would lead to an increase in the size.  With a power law distribution that we find in written language it gives us an advantage however.

## Theoretical throughput
From the research done on the Dasher project there are quite a few interesting points. First of all it presents an rather interesting view onhow to model a system consisting of User, input device and input algorithm. Let's start out by looking at the user. What we are trying to do here is to maximize the bandwidth from the brain to software that is to receive the input.
Starting out from their research each and every finger ought to have a throughput of around 4 bits per second. However on average since all symbols  are not equal with a good enough prediction model, this might be improved with the help of "reverse-compression". Compression on text easily performs around 100% compression. With a prediction model tied to a specific user we might see even better results \*\*) 

## A system with a bias toward coherent text
Consider giving dasher totally random input. The system has a bias towards writing statistically likely words. As such random input is likely to produce somewhat recognizable sentences. As such if you just put in a vector as inputt, you'll have output that sometimes resambles intellegent communication. Compare this to how text can be generated by using markov chains, where words are the subject instead of letters. Here we are doing what spam bots are doing, but we operate on a symbol level rather than on a word level. Compare this to randomingly bashing at your keyboard or doing random voices. This is a way to understand the system, it is more likely to do what you want. If we follow this trajectory then we begin what truly can be achieved if we extend this mode of thought as far as we dare. Where the model step by step is modeled to create better predictions of what we are trying to communicate. 

## Use in conjunction with speech input
One very interesting application is an attempt to use dasher in conjunction with speech input. The problem with speech recognition is how devastiting the occurence of an error is in terms of recoverability. Compare to what happens if you press the wrong key by misstake, one press at the backspace button replace the new key and you are good to go. The experienced user might do it hundreds of times during the course of the day without even noticing. When we are dealing with audio input however, the probability of an error is quite high to beginn with. What makes it devastating from a usability point of view is that two words might sound similar. A setup with dasher where the algorithm presents the potential matches scaled according to frequency creates a usable tandem system, which mitigates the problem. 

Keith V 

## Use for eye tracking
What impresses me with David McKay and the other people behind the Dasher project is their ability to solve problems by making generalizations. So given one of anything they try to replace the constant and go for the extremes. Thus mapping out the extremes of the terrain where proper solutions might be solved. As such they think of not only one input signal but in terms of any input signal. As such any input  method can be used. Therefore eye tracking is a given. Check out the youtube videos below for the human aspects of their work which is not to be forgotten.

## Use for the blind
Correlating very closely to the original idea that got me interested in the subject, a proposal has been made for blind where in practice a binary search is used over a frequency tree. This would in fact instead of being  arithmetic encoding be an implementation of huffman encoding. More on the use of huffman coding, and text-input in a latter stage where I'll present an algorithm based on  N-ary huffman trees. 

## Brilliant takedown
Make  implementation for smartwatches!!

## Integration into HUD
\*\*\*=HUD) 
Dasher can take the menu information from a GNOME appplication and present it as an alphabet. 

## Propposed improvement
- non linear use of screen estate [solves  problem at 17:17]
- thumb in the way on touch (designed for pen)
- Integrate beta taxonomy - to make use of additional digits / multiple dimensions


\*) Or paper to someone who have been carving in stone for his whole life for that matter
\*\*) The corpuses used in the Dasher program is surprisingly small, so there might be room  for improvement here

## Really good1!
HUD - [Implementation of Dasher](https://www.academia.edu/362275/Implementation_of_Dasher_An_Information_Efficient_Input_Mechanism)

## Online resources
[Google Tech talk on Dasher](https://m.youtube.com/watch?v=wpOxbesRNB)
[Dasher in VR](https://youtu.be/FFQgluUwV2U)
[How "Dasher" has touched lives - The human ascpect](https://youtu.be/QxFEUk3J89Q)


[Dasher Radial Menu](https://m.youtube.com/watch?v=5oSfEM8XpH4)	
[Similar thoughts as my ideas](https://forums.tigsource.com/index.php?topic=960)
[HN Post](https://news.ycombinator.com/item?id=17105728)

[Keith V](https://www.keithv.com/software/speechdasher/)
